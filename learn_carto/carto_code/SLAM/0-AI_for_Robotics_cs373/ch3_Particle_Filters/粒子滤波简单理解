所谓粒子滤波就是指：
通过寻找一组在状态空间中传播的随机样本来近似的表示概率密度函数，用样本均值代替积分运算，
进而获得系统状态的最小方差估计的过程，这些样本被形象的称为“粒子”，故而叫粒子滤波。


作者：柳凌峰
链接：https://www.zhihu.com/question/25371476/answer/82278702
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

粒子滤波的本质是monte-carlo模拟，即它是通过对目标区域中物体可能出现的位置概率的一种估测。我们来考虑机器人中的SLAM（Simultaneous Location And Mapping），这个比较直观。1. 假设，我们现在有一辆小车，小车前后左右装了4个距离探测器。我们把这个小车放到一件房间里，这个房间摆放了很多障碍物，有桌子，有椅子。我们假设这个房间的摆放已经被某些方法获知了，这样我们可以拿到一张这个房间的完整地图。2. 当小车刚刚被扔到这个房间，最初它是处于一种懵逼的状态，除了房间本身的摆设，尺寸的信息，自己究竟处于什么位置，它是完全不知道的。3. 最开始，我们会假设这个小车初始的位置可以出现在这个房间的任何一个角落4. 小车开始用距离探测器探测当前它前后左右的障碍物离它有多远，假设这个距离向量是Ds（前后左右一共4个距离）。5. 在这个房间里，任何一个位置周边障碍物与这个位置的距离都是可以计算出来的。我们首先把这个房间均匀地分成M个方块，对每个方块中心位置计算出一个距离向量Dx，我们把这些Dx放在一个集合里面Dset。6. 很自然地，我们可以比较Ds和Dset里面所有的Dx，如果Ds和Dx比较接近，那么我们可以认为小车处于x这个位置的可能性会高一点。7. 现在，小车在房间的不同位置出现的可能性就不是相同的了，自然有地方会高一些（Ds，Dx差异小一些）有一些地方会低一些（Ds，Dx差异大一些）。我们用Px表示小车在每个位置出现的概率。8. 接下来，小车朝着某一个方向移动了一些距离Ms。9. 在移动前，位置x上小车出现的概率是Px，那么这个概率会因为移动而转移到位置x+Ms上，这个过程我们叫做状态转移。10. 所有的Px都会因为小车的移动从最初的位置移动Ms落到新的位置上，这样，小车在每个位置出现的概率Px就彻底经过了一次更新。11. 接下来，我们对Px更高的位置以及这个位置的周边划分出更多，更小的方块出来，而对Px低的区域划分面积大一些的方块，如果Px太小了，那么这个位置直接就被我们排除掉，这个过程我们叫做重采样。之所以划分尺寸不一样的方块，是为了确保在我们假设小车均匀出现在各个位置的概率时，会因为格子的密度不同而在不同区域产生不同的概率分布。12. 然后我们重复6-11步13. 在小车不停的移动中，我们反复计算Px和重新划分位置方块，所起到的作用就是持续地逼近小车在这个房间所处位置的概率分布，一直到它最终落到一个唯一的区域里面。14. 这个计算过程中，有两个问题需要小心处理：第一，如果小车对周边的距离计算有误差，在第11步中我们可能会过早地排除掉一些不应该排除的位置，这是粒子滤波中的die-out问题，直观上就是粒子滤波跑着跑着就不见了，这时候只能重置滤波器或者将滤波器的状态回滚；第二，如果小车的移动距离没有超出一个方块，那么它的状态有可能没法实现转移，如果几次累计 下来，可能造成滤波器没有跟上状态的转移，直观上就是滤波的效果总是慢几拍。15. 大部分的粒子滤波器往往都假设一些很理想的状态转移与重采样的情况。而实际上，由于计算能力和数据采集能力的限制，大部分的粒子滤波往往都是建立在一些稀疏的Dset上面，这样有可能会造成一些隐藏的状态被转移到观察点上。我的理解是，基于稀疏Dset的粒子滤波必须要确保每次的状态转移的偏置量足够大。放狗的理论在视频跟踪里是行得通的，因为它要处理的是一幅完整的图像。